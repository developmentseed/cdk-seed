import json
from typing import List, TypedDict

from ..services import step_functions_client as sfn


class ExecutionDetails(TypedDict):
    executionArn: str
    stateMachineArn: str
    name: str
    status: str
    startDate: int
    stopDate: int
    input: str
    output: str


# Create a base object to avoid error due to the hyphenated key
# `detail-type` in the actual CloudwatchEvent Class
_CloudwatchEventBase = TypedDict("CloudwatchEventBase", {"detail-type": str})


class CloudwatchEvent(_CloudwatchEventBase):
    version: str
    id: str
    source: str
    account: str
    time: str
    region: str
    resources: List[str]
    detail: ExecutionDetails


_SqsMessageAttributesBase = TypedDict(
    "SqsMessageAttributesBase",
    {
        "ApproximateReceiveCount": str,
        "SentTimestamp": str,
        "SenderId": str,
        "ApproximateFirstReceiveTimestamp": str,
    },
)


class SqsMessageAttributes(_SqsMessageAttributesBase):
    pass


class SqsMessage(TypedDict):
    messageId: str
    receiptHandle: str
    body: str
    attributes: SqsMessageAttributes
    messageAttributes: dict
    md5OfBody: str
    eventSource: str
    eventSourceARN: str
    awsRegion: str


_SqsStdQueueEventBase = TypedDict("SqsStdQueueEventBase", {"Records": List[SqsMessage]})


class SqsStdQueueEvent(_SqsStdQueueEventBase):
    """ https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html """

    pass


class StepFunctionInput(TypedDict):
    key: str


class FailedEvent(TypedDict):
    error: str
    cause: str


class EventsTableRecord(TypedDict):
    partition_key: str
    sort_key: str

    sfn_name: str
    sfn_exec_start_ts: int
    event_id: str
    status: str
    record_type: str


class FailedStepDetails(TypedDict):
    failed_step_name: str
    failed_step_input: str
    failed_step_error_message: str
    failed_step_error_name: str


class EventsTableFailedRecord(EventsTableRecord, FailedStepDetails):
    pass


class EventsTableSnapshotRecord(EventsTableRecord):
    sfn_exec_name: str


class EventsTableHistoryRecord(EventsTableRecord):
    stac_item_id: str


class FailedEventsTableSnapshotRecord(
    EventsTableFailedRecord, EventsTableSnapshotRecord
):
    pass


def get_failure_step_details(execution_arn: str) -> FailedStepDetails:
    events = sfn().get_execution_history(executionArn=execution_arn)
    failed_step_name = "UnknownStepName"
    failed_step_input = "UknownInputData"
    failed_step_error_message = "UnkownErrorMessage"
    failed_step_error_name = "UnknownError"
    for event in events["events"]:

        if state_entered := event.get("stateEnteredEventDetails"):
            failed_step_name = state_entered["name"]
            failed_step_input = state_entered["input"]
            continue

        if state_failed := event.get("executionFailedEventDetails"):
            failed_step_error_message = state_failed["cause"]
            failed_step_error_name = state_failed["error"]

            return FailedStepDetails(
                failed_step_name=failed_step_name,
                failed_step_input=failed_step_input,
                failed_step_error_message=failed_step_error_message,
                failed_step_error_name=failed_step_error_name,
            )

    # Returns default values if "executionFailed" is somehow not found
    return FailedStepDetails(
        failed_step_name=failed_step_name,
        failed_step_input=failed_step_input,
        failed_step_error_message=failed_step_error_message,
        failed_step_error_name=failed_step_error_name,
    )


def log_ingestion_in_events_table(event: SqsMessage):
    """
    Handler to process an SQS message generated by a StepFunction FAILED or SUCCEEDED
    EventBridge Rule. First the StepFunction execution history is queried and
    appropriate DynamoDB records are generated to store the successfull ingestion or
    the failure.

    """
    msg: CloudwatchEvent = json.loads(event["body"])
    sfn_input: StepFunctionInput = json.loads(msg["detail"]["input"])

    items = [
        {
            "partition_key": sfn_input["key"].split("/")[-1],  # manifest filename
            "sort_key": sfn_input.get("bundle", {}).get("item_id", "NO_STAC_ITEM_ID"),
            "sfn_exec_name": msg["detail"]["name"],
            "sfn_name": msg["detail"]["stateMachineArn"].split(":")[-1],
            "sfn_exec_start_ts": msg["detail"]["startDate"],
            "event_id": msg["id"],
            "status": msg["detail"]["status"],
            "record_type": "SNAPSHOT",
        },
        {
            "partition_key": sfn_input["key"].split("/")[-1],  # manifest filename
            # step_function execution id
            "sort_key": f"execution:{msg['detail']['name']}",
            "stac_item_id": sfn_input.get("bundle", {}).get(
                "item_id", "NO_STAC_ITEM_ID"
            ),
            "sfn_name": msg["detail"]["stateMachineArn"].split(":")[-1],
            "sfn_exec_start_ts": msg["detail"]["startDate"],
            "event_id": msg["id"],
            "status": msg["detail"]["status"],
            "record_type": "EXECUTION_HISTORY",
        },
    ]

    for item in items:
        if msg["detail"]["status"] == "FAILED":

            item.update(
                get_failure_step_details(execution_arn=msg["detail"]["executionArn"])
            )

            # execution sepecific item, pre-pend "_" to the failed_step_name, in order
            # to exclude that record from showing up in the failures Index
            if "stac_item_id" in item.keys():
                item["_failed_step_name"] = item["failed_step_name"]
                del item["failed_step_name"]

    return items


def new_manifests(events: List[dict]) -> List[dict]:
    # Log all new manifests as failed by default,
    # if the step function succeeds it will overwrite the error message
    # with a success message.
    return [
        {
            "partition_key": event["s3"]["object"]["key"].split("/")[-1],
            "sort_key": "NO_STAC_ITEM_ID",
            "failed_step_name": "Trigger Statemachine from S3",
            "failed_step_error_name": "UnkownError",
            "record_type": "SNAPSHOT",
        }
        for event in events
    ]


def handler(event, context):
    table = dynamodb_resource().Table(os.environ["EVENTS_TABLE"])

    with table.batch_writer() as batch:
        for record in event["Records"]:
            for item in log_ingestion_in_events_table(record):
                batch.put_item(Item=json.loads(json.dumps(item), parse_float=Decimal))
